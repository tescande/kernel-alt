blkback: Write each kthread's pid into xenstore

Write each kthread's pid into xenstore so that it can be ioniced by the
toolstack.  Relative to the VBD, the xenstore key is: queue-NNN/kthread-pid
where NNN is the queue number starting from 0.

Signed-off-by: Ross Lagerwall <ross.lagerwall@citrix.com>
diff --git a/drivers/block/xen-blkback/common.h b/drivers/block/xen-blkback/common.h
index 1d3002d773f7..e41d5e246c7e 100644
--- a/drivers/block/xen-blkback/common.h
+++ b/drivers/block/xen-blkback/common.h
@@ -231,7 +231,14 @@ struct xen_vbd {
 	unsigned int		overflow_max_grants:1;
 };
 
-struct backend_info;
+struct backend_info {
+	struct xenbus_device	*dev;
+	struct xen_blkif	*blkif;
+	struct xenbus_watch	backend_watch;
+	unsigned		major;
+	unsigned		minor;
+	char			*mode;
+};
 
 /* Number of requests that we can fit in a ring */
 #define XEN_BLKIF_REQS_PER_PAGE		32
@@ -365,8 +372,12 @@ struct pending_req {
 #define xen_blkif_get(_b) (atomic_inc(&(_b)->refcnt))
 #define xen_blkif_put(_b)				\
 	do {						\
-		if (atomic_dec_and_test(&(_b)->refcnt))	\
-			schedule_work(&(_b)->free_work);\
+		if (atomic_dec_and_test(&(_b)->refcnt))	{ \
+			get_device(&(_b)->be->dev->dev); \
+			if (!schedule_work(&(_b)->free_work)) { \
+				put_device(&(_b)->be->dev->dev); \
+			} \
+                } \
 	} while (0)
 
 struct phys_req {
diff --git a/drivers/block/xen-blkback/xenbus.c b/drivers/block/xen-blkback/xenbus.c
index dc954fbc664f..c31dc95a3513 100644
--- a/drivers/block/xen-blkback/xenbus.c
+++ b/drivers/block/xen-blkback/xenbus.c
@@ -26,15 +26,6 @@
 /* On the XenBus the max length of 'ring-ref%u'. */
 #define RINGREF_NAME_LEN (20)
 
-struct backend_info {
-	struct xenbus_device	*dev;
-	struct xen_blkif	*blkif;
-	struct xenbus_watch	backend_watch;
-	unsigned		major;
-	unsigned		minor;
-	char			*mode;
-};
-
 static struct kmem_cache *xen_blkif_cachep;
 static void connect(struct backend_info *);
 static int connect_ring(struct backend_info *);
@@ -81,12 +72,26 @@ static int blkback_name(struct xen_blkif *blkif, char *buf)
 	return 0;
 }
 
+static void cleanup_xs_pid(char *buf, size_t size, const char *nodename,
+			   unsigned int ring)
+{
+	memset(buf, 0, size);
+	snprintf(buf, size, "%s/queue-%u", nodename, ring);
+	xenbus_rm(XBT_NIL, buf, "kthread-pid");
+	memset(buf, 0, size);
+	snprintf(buf, size, "queue-%u", ring);
+	xenbus_rm(XBT_NIL, nodename, buf);
+}
+
 static void xen_update_blkif_status(struct xen_blkif *blkif)
 {
 	int err;
 	char name[TASK_COMM_LEN];
 	struct xen_blkif_ring *ring;
 	int i;
+	char *xspath;
+	size_t xspathsize;
+	const size_t xenstore_path_ext_size = 11; /* sufficient for "/queue-NNN" */
 
 	/* Not ready to connect? */
 	if (!blkif->rings || !blkif->rings[0].irq || !blkif->vbd.bdev)
@@ -114,6 +119,13 @@ static void xen_update_blkif_status(struct xen_blkif *blkif)
 	}
 	invalidate_inode_pages2(blkif->vbd.bdev->bd_inode->i_mapping);
 
+	xspathsize = strlen(blkif->be->dev->nodename) + xenstore_path_ext_size;
+	xspath = kmalloc(xspathsize, GFP_KERNEL);
+	if (!xspath) {
+		xenbus_dev_fatal(blkif->be->dev, -ENOMEM, "allocating xspath");
+		return;
+	}
+
 	for (i = 0; i < blkif->nr_rings; i++) {
 		ring = &blkif->rings[i];
 		ring->xenblkd = kthread_run(xen_blkif_schedule, ring, "%s-%d", name, i);
@@ -124,14 +136,28 @@ static void xen_update_blkif_status(struct xen_blkif *blkif)
 					"start %s-%d xenblkd", name, i);
 			goto out;
 		}
+
+		memset(xspath, 0, xspathsize);
+		snprintf(xspath, xspathsize, "%s/queue-%d",
+			 blkif->be->dev->nodename, i);
+		err = xenbus_printf(XBT_NIL, xspath, "kthread-pid",
+				    "%d", ring->xenblkd->pid);
+		if (err) {
+			xenbus_dev_error(blkif->be->dev, err, "writing kthread-pid");
+			kthread_stop(ring->xenblkd);
+			goto out;
+		}
 	}
+	kfree(xspath);
 	return;
 
 out:
 	while (--i >= 0) {
 		ring = &blkif->rings[i];
 		kthread_stop(ring->xenblkd);
+		cleanup_xs_pid(xspath, xspathsize, blkif->be->dev->nodename, i);
 	}
+	kfree(xspath);
 	return;
 }
 
@@ -245,6 +271,14 @@ static int xen_blkif_disconnect(struct xen_blkif *blkif)
 	struct pending_req *req, *n;
 	unsigned int j, r;
 	bool busy = false;
+	char *xspath;
+	size_t xspathsize;
+	const size_t xenstore_path_ext_size = 11; /* sufficient for "/queue-NNN" */
+
+	xspathsize = strlen(blkif->be->dev->nodename) + xenstore_path_ext_size;
+	xspath = kmalloc(xspathsize, GFP_KERNEL);
+	if (!xspath)
+		dev_warn(&blkif->be->dev->dev, "allocating xspath (%d)", -ENOMEM);
 
 	for (r = 0; r < blkif->nr_rings; r++) {
 		struct xen_blkif_ring *ring = &blkif->rings[r];
@@ -255,6 +289,9 @@ static int xen_blkif_disconnect(struct xen_blkif *blkif)
 
 		if (ring->xenblkd) {
 			kthread_stop(ring->xenblkd);
+			if (xspath)
+				cleanup_xs_pid(xspath, xspathsize,
+					       blkif->be->dev->nodename, r);
 			ring->xenblkd = NULL;
 			wake_up(&ring->shutdown_wq);
 		}
@@ -304,6 +341,7 @@ static int xen_blkif_disconnect(struct xen_blkif *blkif)
 		WARN_ON(i != (XEN_BLKIF_REQS_PER_PAGE * blkif->nr_ring_pages));
 		ring->active = false;
 	}
+	kfree(xspath);
 	if (busy)
 		return -EBUSY;
 
@@ -322,6 +360,11 @@ static int xen_blkif_disconnect(struct xen_blkif *blkif)
 static void xen_blkif_free(struct xen_blkif *blkif)
 {
 	WARN_ON(xen_blkif_disconnect(blkif));
+	/*
+	 * Drop the ref taken in xen_blkif_put. This ensures nodename can be
+	 * safely used in xen_blkif_disconnect.
+	 */
+	put_device(&blkif->be->dev->dev);
 	xen_vbd_free(&blkif->vbd);
 	kfree(blkif->be->mode);
 	kfree(blkif->be);
